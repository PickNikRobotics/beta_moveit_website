---
layout: post
author: Boston Cleek
comments: false
date: 2020-09-17 00:00:00 -0600
title: New MoveIt Grasping Capabilities using Deep Learning
media_type: image
media_link: "/assets/images/blog_posts/2020-09-15-grasp.png"
description: Grasping using Deep Learning now available in the MoveIt Task Constructor
categories:
- 3-D perception
- MoveIt
- Grasping
- Deep Learning

---
MoveIt now supports robust grasp pose generation using deep learning. Pick and place robots equipped with a depth camera and either a parallel jaw or suction gripper can increase productivity when paired with deep learning. The MoveIt Task Constructor provides an interface for any grasp pose generation algorithm making MoveIt’s pick and place capabilities more flexible and powerful.

Currently, the [Grasp Pose Detection](https://github.com/atenpas/gpd) (GPD) library and [Dex-Net](https://berkeleyautomation.github.io/dex-net/) are being used to detect 6-DOF grasp poses given 3D sensor data. GPD is capable of generating grasp poses for parallel jaw grippers and Dex-Net works with both parallel jaw and suction grippers. These neural networks are trained on datasets containing millions of images allowing them to pick novel objects from cluttered scenes.

The depth camera can either mount to a link on the robot or remain stationary. If the camera is mounted to a link or if multiple cameras are used, it is possible to reconstruct a 3D point cloud or collect depth images from multiple viewpoints. This technique enables grasp pose generators to sample more grasp candidates from views that would otherwise be occluded.

The UR5 below uses a grasp pose generated by GPD to pick up a box. The point cloud was acquired by the RealSense camera to the left of the robot.

![](/assets/images/blog_posts/2020-09-16-gpd_ur5_short.gif)

The animation below shows the capabilities of deep learning for grasp pose generation. Dex-Net achieves greater performance in terms of successfully grasping objects, reliability, and computational speed when compared to GPD.

![](/assets/images/blog_posts/2020-09-15-gqcnn_cylinder_gazebo.gif)

![](/assets/images/blog_posts/2020-09-15-gqcnn_barclamp_gazebo.gif)

To learn more about how to use GPD and Dex-Net within MoveIt see the [Deep Grasp Tutorial](https://github.com/bostoncleek/moveit_tutorials/blob/new-deep-grasp_tutorial/doc/moveit_deep_grasps/moveit_deep_grasps_tutorial.rst) and the [Deep Grasp Demo](https://github.com/PickNikRobotics/deep_grasp_demo). The demo contains detailed instructions for acquiring data by simulating depth sensors and executing motion plans in Gazebo.

![](/assets/images/blog_posts/line.png)

**Acclerate Your Robotics Development**

About [PickNik](https://picknik.ai/): Robots are complex systems that require a wide breadth of expert knowledge spanning multiple disciplines, making robotics development extremely difficult and costly. Since 2015, PickNik’s mission has been to address this technical challenge while dramatically reducing development time for advanced robotic applications. To achieve this, PickNik supports and collaborates with the worldwide open source robotics movement, providing companies with cutting edge research and barrier-free open source software.

PickNik is rooted with a strong background in robotics theory combined with applied software experience to provide unique solutions. Robotics companies including Google, Amazon, Kindred, and many others are partnering with PickNik to develop robotic applications to address the toughest issues through software consulting, custom development, and other initiatives. By working together, we can accomplish far more than by working alone.

If you would like more information please contact us at [https://picknik.ai/connect/](https://picknik.ai/connect/ "https://picknik.ai/connect/")